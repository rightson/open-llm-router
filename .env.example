# PostgreSQL configuration for Open-WebUI
OPENWEBUI_DB_USER=openwebui_user
OPENWEBUI_DB_PASSWORD=your_secure_password_here
OPENWEBUI_DB_NAME=openwebui_db
OPENWEBUI_HOST=localhost
OPENWEBUI_PORT=8087

# Database connection settings
DB_HOST=localhost
DB_PORT=5432

# PostgreSQL admin password (for initialization)
POSTGRES_PASSWORD=your_postgres_admin_password

# Database URL for Open-WebUI (constructed from above variables)
DATABASE_URL=postgresql://${OPENWEBUI_DB_USER}:${OPENWEBUI_DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${OPENWEBUI_DB_NAME}

# LLM API Configuration
# These keys are referenced by conf/config.yml using os.environ/KEY_NAME format
OPENAI_API_KEY=your_openai_api_key_here
GROK_API_KEY=your_grok_api_key_here
CLAUDE_API_KEY=your_claude_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here

# Service Ports
LLM_ROUTER_PORT=8086
LLM_ROUTER_HOST=localhost
OPEN_LLM_ROUTER_LOG_DIR="$HOME/workspace/open-llm-router/logs"

# Optional: Custom model configurations
# ENABLE_OPENAI_API=true
# HF_HUB_OFFLINE=1

# Ollama Configuration (used by ./manage.sh ollama)
# These environment variables are loaded when running ollama serve
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_ORIGINS=*
# OLLAMA_FLASH_ATTENTION=1
# OLLAMA_CONTEXT_LENGTH=8192
# OLLAMA_MODELS=/path/to/models
# OLLAMA_KEEP_ALIVE=5m
# OLLAMA_NUM_PARALLEL=1
# OLLAMA_MAX_LOADED_MODELS=1
# OLLAMA_DEBUG=false
# OLLAMA_KV_CACHE_TYPE=q8_0

# LM Studio Configuration (used by ./manage.sh scan-models)
# LMSTUDIO_HOST=http://localhost:1234
